# -*- coding: utf-8 -*-
"""Spam Mail Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QoSo0gS6shKcBXSLhxZf9AVhUhydji2a

Importing Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB
import streamlit as st

"""Data Collection"""

dataset = pd.read_csv('/content/spam.csv', encoding='latin-1')

dataset.head()

print(dataset.shape)

"""Data cleaning"""

dataset.drop_duplicates(inplace=True)

dataset.rename(columns={'v1': 'category', 'v2': 'message'}, inplace=True)

dataset['category'] = dataset['category'].replace({'ham': 'Not spam', 'spam': 'Spam'})
print(dataset.head())

"""Data Training"""

mess= dataset['message']
cat= dataset['category']



(mess_train, mess_test, cat_train, cat_test) = train_test_split(mess, cat, test_size=0.2, random_state=42)

cv = CountVectorizer(stop_words='english')
features =cv.fit_transform(mess_train)
mess_train_count = cv.transform(mess_train)

"""Create A Model"""

model =MultinomialNB()
model.fit(features, cat_train)

features_test = cv.transform(mess_test)
print(model.score(features_test, cat_test))



"""Predict Data"""

def predict_spam(message):
    message_count = cv.transform([message])
    prediction = model.predict(message_count)
    return prediction[0]

#get user input to predict
userMessage = input("Enter a message: ")
prediction = predict_spam(userMessage)
print(prediction)

